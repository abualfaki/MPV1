{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2dd1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the Amazon RDS PostgreSQL database!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Database connection details\n",
    "host = \"loandata-instance-1.cn6sa80g6v9a.us-east-2.rds.amazonaws.com\"\n",
    "database = \"loans_data\"\n",
    "user = \"abu\"\n",
    "password = \"Mpv1loansdata\"\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        user=user,\n",
    "        password=password\n",
    "    )\n",
    "    print(\"Connected to the Amazon RDS PostgreSQL database!\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53aaa405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table accepted_loans truncated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading accepted_loans:   3%|‚ñè     | 74000/2260701 [00:05<02:48, 12974.96rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while loading data into accepted_loans: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n",
      "Table rejected_loans truncated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading rejected_loans:   2%|    | 601000/27648741 [00:07<05:56, 75871.13rows/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m         connection \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mconnection  \u001b[38;5;66;03m# Get the raw psycopg2 connection\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         load_data_with_progress(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccepted_loans\u001b[39m\u001b[38;5;124m'\u001b[39m, accepted_csv, connection, chunk_size)\n\u001b[0;32m---> 50\u001b[0m         load_data_with_progress(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrejected_loans\u001b[39m\u001b[38;5;124m'\u001b[39m, rejected_csv, connection, chunk_size)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 35\u001b[0m, in \u001b[0;36mload_data_with_progress\u001b[0;34m(table_name, csv_path, connection, chunk_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_temp.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cursor:\n\u001b[0;32m---> 35\u001b[0m         cursor\u001b[38;5;241m.\u001b[39mcopy_expert(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOPY \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m FROM STDIN WITH CSV HEADER\u001b[39m\u001b[38;5;124m\"\u001b[39m, file)\n\u001b[1;32m     37\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_temp.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Remove temp file after loading\u001b[39;00m\n\u001b[1;32m     38\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))  \u001b[38;5;66;03m# Update progress bar\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Database connection details\n",
    "db_url = \"postgresql://abubakaral-faki:your_password@localhost:5432/loans_data\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Paths to the CSV files\n",
    "accepted_csv = \"/Users/abubakaral-faki/Documents/Data Project/MPV1/data/raw/accepted_2007_to_2018Q4.csv\"\n",
    "rejected_csv = \"/Users/abubakaral-faki/Documents/Data Project/MPV1/data/raw/rejected_2007_to_2018Q4.csv\"\n",
    "\n",
    "# Chunk size for processing\n",
    "chunk_size = 1000  # Adjust based on your system's memory capacity\n",
    "\n",
    "# Function to truncate tables and load data\n",
    "def load_data_with_progress(table_name, csv_path, connection, chunk_size):\n",
    "    try:\n",
    "        # Truncate the table\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(f\"TRUNCATE TABLE {table_name};\")\n",
    "            print(f\"Table {table_name} truncated successfully.\")\n",
    "        \n",
    "        # Use tqdm for progress tracking\n",
    "        total_rows = sum(1 for _ in open(csv_path)) - 1  # Total rows excluding the header\n",
    "        with tqdm(total=total_rows, desc=f\"Loading {table_name}\", unit=\"rows\") as pbar:\n",
    "            \n",
    "            for chunk in pd.read_csv(csv_path, chunksize=chunk_size):\n",
    "                chunk.to_csv(f\"{table_name}_temp.csv\", index=False)  # Save chunk to a temp file\n",
    "                \n",
    "                with open(f\"{table_name}_temp.csv\", 'r') as file:\n",
    "                    with connection.cursor() as cursor:\n",
    "                        cursor.copy_expert(f\"COPY {table_name} FROM STDIN WITH CSV HEADER\", file)\n",
    "                        \n",
    "                os.remove(f\"{table_name}_temp.csv\")  # Remove temp file after loading\n",
    "                pbar.update(len(chunk))  # Update progress bar\n",
    "\n",
    "        print(f\"Data loaded into {table_name} successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading data into {table_name}: {e}\")\n",
    "\n",
    "# Main script to load data\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        connection = conn.connection  # Get the raw psycopg2 connection\n",
    "        load_data_with_progress('accepted_loans', accepted_csv, connection, chunk_size)\n",
    "        load_data_with_progress('rejected_loans', rejected_csv, connection, chunk_size)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2fb90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
